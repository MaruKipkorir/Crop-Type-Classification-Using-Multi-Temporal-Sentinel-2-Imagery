{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 12109700,
          "datasetId": 7624279,
          "databundleVersionId": 12639685
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "08Z8fnNuofqY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T09:47:54.002356Z",
          "iopub.execute_input": "2025-06-16T09:47:54.002764Z",
          "iopub.status.idle": "2025-06-16T09:47:54.008994Z",
          "shell.execute_reply.started": "2025-06-16T09:47:54.002736Z",
          "shell.execute_reply": "2025-06-16T09:47:54.007998Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and prepare the dataset (csv and images)"
      ],
      "metadata": {
        "id": "IGqFXbKoJVtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = pd.read_csv('TrainDataset.csv')\n",
        "train_dataset.head()"
      ],
      "metadata": {
        "id": "sw7AFTRzWYxJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T09:48:05.308210Z",
          "iopub.execute_input": "2025-06-16T09:48:05.308715Z",
          "iopub.status.idle": "2025-06-16T09:48:05.390364Z",
          "shell.execute_reply.started": "2025-06-16T09:48:05.308675Z",
          "shell.execute_reply": "2025-06-16T09:48:05.389492Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the filename from the full path\n",
        "train_dataset['tif_name'] = train_dataset['tifPath'].str.split('/').str[-1]\n",
        "# Drop rows that contain missing values\n",
        "train_dataset.dropna(inplace=True)\n",
        "# Sort the DataFrame based on the filename so that the dataset is ordered by the image filenames\n",
        "train_dataset.sort_values(by='tif_name', inplace=True)"
      ],
      "metadata": {
        "id": "IN6636hc_Zx5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:02:38.160655Z",
          "iopub.execute_input": "2025-06-16T08:02:38.160904Z",
          "iopub.status.idle": "2025-06-16T08:02:38.186761Z",
          "shell.execute_reply.started": "2025-06-16T08:02:38.160866Z",
          "shell.execute_reply": "2025-06-16T08:02:38.186016Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the training images >>>REPLACE WITH YOUR OWN\n",
        "image_dir ='train'\n",
        "\n",
        "# Get a sorted list of all filenames in the image directory\n",
        "files = sorted(os.listdir(image_dir))\n",
        "# Create full file paths by joining the directory path with each filename\n",
        "file_paths = [os.path.join(image_dir, f) for f in files]"
      ],
      "metadata": {
        "id": "1m3k3xYWGreV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:02:38.012778Z",
          "iopub.execute_input": "2025-06-16T08:02:38.012977Z",
          "iopub.status.idle": "2025-06-16T08:02:38.159863Z",
          "shell.execute_reply.started": "2025-06-16T08:02:38.012962Z",
          "shell.execute_reply": "2025-06-16T08:02:38.159125Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# After sorting the DataFrame based on filename and obtaining sorted list of all filenames in the image directory,\n",
        "# the order of images and the corresponding labels in the DataFrame should now align.\n",
        "\n",
        "# Confirm that the number of image paths matches the number of rows in the DataFrame.\n",
        "print(\"Number of image files:\", len(file_paths))\n",
        "print(\"Number of DataFrame entries:\", train_dataset.shape[0])"
      ],
      "metadata": {
        "id": "F9iM51-qM6lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the full image file paths to the column 'tifPath' in the dataframe\n",
        "train_dataset['tifPath'] = file_paths\n",
        "# Verify the column has been updated.\n",
        "train_dataset.head()"
      ],
      "metadata": {
        "id": "_byuSryvH_lz",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:02:38.187761Z",
          "iopub.execute_input": "2025-06-16T08:02:38.188052Z",
          "iopub.status.idle": "2025-06-16T08:02:38.210604Z",
          "shell.execute_reply.started": "2025-06-16T08:02:38.188028Z",
          "shell.execute_reply": "2025-06-16T08:02:38.209917Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the labels to be zero-indexed as expected by most ML models.\n",
        "train_dataset['label'] = train_dataset['class']-1"
      ],
      "metadata": {
        "id": "aMHfZ9G_PIuq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:02:38.211306Z",
          "iopub.execute_input": "2025-06-16T08:02:38.211487Z",
          "iopub.status.idle": "2025-06-16T08:02:38.215866Z",
          "shell.execute_reply.started": "2025-06-16T08:02:38.211473Z",
          "shell.execute_reply": "2025-06-16T08:02:38.215146Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and validation sets.\n",
        "# Stratified sampling ensures that the class distribution is maintained across both sets.\n",
        "train_df, val_df = train_test_split(\n",
        "    train_dataset,\n",
        "    test_size=0.2,\n",
        "    stratify=train_dataset['Target'],\n",
        "    random_state=2\n",
        ")"
      ],
      "metadata": {
        "id": "vJF-rBWrAbPC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:02:38.218473Z",
          "iopub.execute_input": "2025-06-16T08:02:38.218725Z",
          "iopub.status.idle": "2025-06-16T08:02:38.912412Z",
          "shell.execute_reply.started": "2025-06-16T08:02:38.218710Z",
          "shell.execute_reply": "2025-06-16T08:02:38.911574Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, models\n",
        "from keras.optimizers import SGD, Adam\n",
        "from imagecodecs import imread"
      ],
      "metadata": {
        "id": "Y3-E8RVtNLWA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:02:38.913365Z",
          "iopub.execute_input": "2025-06-16T08:02:38.913933Z",
          "iopub.status.idle": "2025-06-16T08:03:00.637250Z",
          "shell.execute_reply.started": "2025-06-16T08:02:38.913870Z",
          "shell.execute_reply": "2025-06-16T08:03:00.636438Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import Sequence, to_categorical\n",
        "\n",
        "class SatelliteImageGenerator(Sequence):\n",
        "    \"\"\"\n",
        "    Custom data generator for satellite image classification using Keras Sequence.\n",
        "\n",
        "    Loads multi-band TIFF images from file paths listed in a DataFrame,\n",
        "    normalizes them, resizes them, and returns batches with one-hot encoded labels.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, batch_size=32, image_size=(224, 224), shuffle=True, num_classes=3):\n",
        "        self.df = df.reset_index(drop=True) # Reset DataFrame index\n",
        "        self.batch_size = batch_size # Number of samples per batch\n",
        "        self.image_size = image_size # Target image size (H, W)\n",
        "        self.shuffle = shuffle # Whether to shuffle data after each epoch\n",
        "        self.indices = np.arange(len(df)) # Index tracker\n",
        "        self.num_classes = num_classes # Number of target classes\n",
        "        self.on_epoch_end() # Shuffle if needed\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns total number of batches per epoch\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generates one batch of data\"\"\"\n",
        "        # Get indices for the batch\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        # Get file paths and labels for those indices\n",
        "        batch_paths = self.df.loc[batch_indices, 'tifPath'].values\n",
        "        batch_labels = self.df.loc[batch_indices, 'label'].values\n",
        "\n",
        "        # Load and preprocess images\n",
        "        batch_images = []\n",
        "        for path in batch_paths:\n",
        "            img = imread(path).astype('float32') # Read image as float32\n",
        "            img = tf.image.resize(img, self.image_size) # Resize to target size\n",
        "            img = img / 15000.0  # Normalize based on sensor range. Range is (0-15000). Normalize to (0-1)\n",
        "            batch_images.append(img)\n",
        "\n",
        "        # Stack images into a tensor and one-hot encode labels\n",
        "        batch_images = tf.stack(batch_images)\n",
        "        batch_labels = to_categorical(batch_labels, num_classes=self.num_classes)\n",
        "\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "      # Shuffle indices after each epoch\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "metadata": {
        "id": "YDFhrg-TlVK2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:04:58.043916Z",
          "iopub.execute_input": "2025-06-16T08:04:58.044213Z",
          "iopub.status.idle": "2025-06-16T08:04:58.052569Z",
          "shell.execute_reply.started": "2025-06-16T08:04:58.044194Z",
          "shell.execute_reply": "2025-06-16T08:04:58.051807Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation data generators with shuffling disabled during validation for consistent evaluation\n",
        "train_gen = SatelliteImageGenerator(train_df, batch_size=32, image_size=(224, 224))\n",
        "val_gen = SatelliteImageGenerator(val_df, batch_size=32, image_size=(224, 224), shuffle=False)"
      ],
      "metadata": {
        "id": "BAPeaens5LIx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:05:11.374196Z",
          "iopub.execute_input": "2025-06-16T08:05:11.374875Z",
          "iopub.status.idle": "2025-06-16T08:05:11.379594Z",
          "shell.execute_reply.started": "2025-06-16T08:05:11.374851Z",
          "shell.execute_reply": "2025-06-16T08:05:11.378861Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_builder(input_shape=(224, 224, 12), num_classes=3):\n",
        "    \"\"\"\n",
        "    Builds a VGG16-inspired Convolutional Neural Network model adapted for multi-spectral input.\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled Keras model.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Each block has:\n",
        "    # Conv layers with 'n' number of 3x3 filters\n",
        "    # each followed by BatchNorm, ReLU\n",
        "    # and ends with a MaxPooling layer.\n",
        "\n",
        "    # Block 1 >>64 filters, 2 layers\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "    # Block 2 >>128 filters, 2 layers\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "    # Block 3 >>256 filters, 3 layers\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "    # Block 4 >>512 filters, 3 layers\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "    # Block 5 >>512 filters, 3 layers\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "    # Fully connected\n",
        "    # Two dense layers with 4096 units with BatchNorm and ReLU\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(4096)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dense(4096)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Final classification layer\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"model1\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "GeqCqfNx-rjI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:03:00.651996Z",
          "iopub.status.idle": "2025-06-16T08:03:00.652238Z",
          "shell.execute_reply.started": "2025-06-16T08:03:00.652132Z",
          "shell.execute_reply": "2025-06-16T08:03:00.652145Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = CNN_builder()\n",
        "\n",
        "# Initialize the optimizer (Stochastic Gradient Descent with a learning rate)\n",
        "optimizer = SGD(learning_rate=0.001)\n",
        "\n",
        "# Compile the model with categorical crossentropy loss and track accuracy during training\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Rx0g-UUq-6Ay",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:03:00.654758Z",
          "iopub.status.idle": "2025-06-16T08:03:00.655097Z",
          "shell.execute_reply.started": "2025-06-16T08:03:00.654988Z",
          "shell.execute_reply": "2025-06-16T08:03:00.654999Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import  ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# Callback to reduce learning rate when validation loss plateaus\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss', # Metric to monitor\n",
        "    factor=0.5, # Reduce learning rate by this factor\n",
        "    patience=5, # Number of epochs with no improvement after which to reduce LR\n",
        "    verbose=1, # Print messages when LR is updated\n",
        "    min_lr=1e-6 # Lower bound on the learning rate\n",
        ")\n",
        "\n",
        "# Callback to save the best model (based on validation loss)\n",
        "modelcheckpoint = ModelCheckpoint(filepath=\"model1.keras\",save_best_only=True, monitor=\"val_loss\")\n",
        "\n",
        "# Define callbacks list to pass during training\n",
        "callback_list = [lr_scheduler, modelcheckpoint]"
      ],
      "metadata": {
        "id": "Hg4RLUIr-0vx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:03:00.656134Z",
          "iopub.status.idle": "2025-06-16T08:03:00.656434Z",
          "shell.execute_reply.started": "2025-06-16T08:03:00.656255Z",
          "shell.execute_reply": "2025-06-16T08:03:00.656270Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_gen, validation_data=val_gen, epochs=70, callbacks=callback_list)"
      ],
      "metadata": {
        "id": "9sIg1Xs2_Z05",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:03:00.657819Z",
          "iopub.status.idle": "2025-06-16T08:03:00.658113Z",
          "shell.execute_reply.started": "2025-06-16T08:03:00.657985Z",
          "shell.execute_reply": "2025-06-16T08:03:00.657999Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert training history to DataFrame\n",
        "metrics = pd.DataFrame(history.history)"
      ],
      "metadata": {
        "id": "yjqj29c8oH6s",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:03:00.659965Z",
          "iopub.status.idle": "2025-06-16T08:03:00.660294Z",
          "shell.execute_reply.started": "2025-06-16T08:03:00.660136Z",
          "shell.execute_reply": "2025-06-16T08:03:00.660149Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss\n",
        "metrics[['loss','val_loss']].plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tDH85yR6oXMm",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:03:00.661171Z",
          "iopub.status.idle": "2025-06-16T08:03:00.661473Z",
          "shell.execute_reply.started": "2025-06-16T08:03:00.661321Z",
          "shell.execute_reply": "2025-06-16T08:03:00.661334Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy\n",
        "metrics[['accuracy','val_accuracy']].plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GUv5AZkBehLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best saved model and evaluate it on the validation set\n",
        "model = keras.models.load_model(\"model1.keras\")\n",
        "val_loss, val_accuracy = model.evaluate(val_gen)\n",
        "print(f\"\\nValidation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "aBKpzYMx81NO",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:03:00.662422Z",
          "iopub.status.idle": "2025-06-16T08:03:00.662618Z",
          "shell.execute_reply.started": "2025-06-16T08:03:00.662524Z",
          "shell.execute_reply": "2025-06-16T08:03:00.662532Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and prepare the test set. Very similar to how the training set has been prepared."
      ],
      "metadata": {
        "id": "3dy6pgUUfRZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('TestDataset.csv')\n",
        "# Extract the filename from the full path\n",
        "test_df['tif_name'] = test_df['tifPath'].str.split('/').str[-1]\n",
        "# Make a copy of the test DataFrame\n",
        "test = test_df.copy()"
      ],
      "metadata": {
        "id": "amWf9HgEW7it",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:06:37.471522Z",
          "iopub.execute_input": "2025-06-16T08:06:37.472019Z",
          "iopub.status.idle": "2025-06-16T08:06:37.495403Z",
          "shell.execute_reply.started": "2025-06-16T08:06:37.471999Z",
          "shell.execute_reply": "2025-06-16T08:06:37.494905Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows that contain missing values\n",
        "test_df.dropna(inplace=True)\n",
        "# Sort the DataFrame based on the filename so that the dataset is ordered by the image filenames\n",
        "test_df.sort_values(by='tif_name', inplace=True)"
      ],
      "metadata": {
        "id": "bbHH-5wce8uv",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:06:37.496036Z",
          "iopub.execute_input": "2025-06-16T08:06:37.496222Z",
          "iopub.status.idle": "2025-06-16T08:06:37.503808Z",
          "shell.execute_reply.started": "2025-06-16T08:06:37.496208Z",
          "shell.execute_reply": "2025-06-16T08:06:37.503160Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the test images >>>REPLACE WITH YOUR OWN\n",
        "test_image_dir = 'test'"
      ],
      "metadata": {
        "id": "1KHImNoyWsS5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:06:37.504459Z",
          "iopub.execute_input": "2025-06-16T08:06:37.504713Z",
          "iopub.status.idle": "2025-06-16T08:06:37.517098Z",
          "shell.execute_reply.started": "2025-06-16T08:06:37.504687Z",
          "shell.execute_reply": "2025-06-16T08:06:37.516461Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sorted list of all filenames in the test image directory\n",
        "test_files = sorted(os.listdir(test_image_dir))\n",
        "\n",
        "# Create full file paths by joining the directory path with each filename\n",
        "test_file_paths = [os.path.join(test_image_dir, f) for f in test_files]\n",
        "\n",
        "# Assign the full image file paths to the column 'tifPath' in the dataframe\n",
        "test_df['tifPath'] = test_file_paths"
      ],
      "metadata": {
        "id": "GuTAMslBsxHL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:06:37.518935Z",
          "iopub.execute_input": "2025-06-16T08:06:37.519124Z",
          "iopub.status.idle": "2025-06-16T08:06:37.575277Z",
          "shell.execute_reply.started": "2025-06-16T08:06:37.519109Z",
          "shell.execute_reply": "2025-06-16T08:06:37.574612Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class SatellitePredictionGenerator(Sequence):\n",
        "    \"\"\"Data generator for inference\"\"\"\n",
        "    def __init__(self, df, batch_size=32, image_size=(224, 224), shuffle=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get batch indices and corresponding file paths\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_paths = self.df.loc[batch_indices, 'tifPath'].values\n",
        "\n",
        "        batch_images = []\n",
        "        for path in batch_paths:\n",
        "            img = imread(path).astype('float32') # Load image\n",
        "            img = tf.image.resize(img, self.image_size) # Resize\n",
        "            img = img / 15000.0  # Normalize to (0-1)\n",
        "            batch_images.append(img)\n",
        "\n",
        "        return (tf.stack(batch_images),) # Return as tuple for Keras compatibility\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "metadata": {
        "id": "NSmaEeuIYyK_",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:06:37.576088Z",
          "iopub.execute_input": "2025-06-16T08:06:37.576790Z",
          "iopub.status.idle": "2025-06-16T08:06:37.582488Z",
          "shell.execute_reply.started": "2025-06-16T08:06:37.576772Z",
          "shell.execute_reply": "2025-06-16T08:06:37.581835Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prediction generator for the test set\n",
        "pred_gen = SatellitePredictionGenerator(test_df, batch_size=32, image_size=(224, 224))\n",
        "\n",
        "# Run inference\n",
        "predictions = model.predict(pred_gen)\n",
        "\n",
        "# Convert probability distributions to class indices\n",
        "pred_classes = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "id": "gl8SefEkdN0Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:06:37.583100Z",
          "iopub.execute_input": "2025-06-16T08:06:37.583603Z",
          "iopub.status.idle": "2025-06-16T08:07:26.474849Z",
          "shell.execute_reply.started": "2025-06-16T08:06:37.583587Z",
          "shell.execute_reply": "2025-06-16T08:07:26.474265Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign predicted class indices to a new column\n",
        "test_df['label'] = pred_classes\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "2r5KH-5pdtId",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:07:26.475672Z",
          "iopub.execute_input": "2025-06-16T08:07:26.475949Z",
          "iopub.status.idle": "2025-06-16T08:07:26.485167Z",
          "shell.execute_reply.started": "2025-06-16T08:07:26.475919Z",
          "shell.execute_reply": "2025-06-16T08:07:26.484576Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Map class indices to crop names\n",
        "class_to_label = {\n",
        "    0: 'Cocoa',\n",
        "    1: 'Palm',\n",
        "    2: 'Rubber'\n",
        "}\n",
        "\n",
        "# Create the 'Target' column using the mapping\n",
        "test_df['Target'] = test_df['label'].map(class_to_label)"
      ],
      "metadata": {
        "id": "vKUCEy_FlTMs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:07:26.485797Z",
          "iopub.execute_input": "2025-06-16T08:07:26.485991Z",
          "iopub.status.idle": "2025-06-16T08:07:26.502693Z",
          "shell.execute_reply.started": "2025-06-16T08:07:26.485977Z",
          "shell.execute_reply": "2025-06-16T08:07:26.502156Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the predictions with the original test DataFrame\n",
        "test = test.merge(test_df[['ID','Target']], on='ID', how='left')"
      ],
      "metadata": {
        "id": "rIoLBhpMnIiW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:07:26.503417Z",
          "iopub.execute_input": "2025-06-16T08:07:26.503714Z",
          "iopub.status.idle": "2025-06-16T08:07:26.523672Z",
          "shell.execute_reply.started": "2025-06-16T08:07:26.503689Z",
          "shell.execute_reply": "2025-06-16T08:07:26.523070Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are upto 12 images per ID (corresponding to months of the year). Only one submission is made per ID."
      ],
      "metadata": {
        "id": "LB3l1OPwnv-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the prefix from the 'ID' by removing the section after the underscore\n",
        "test['prefix'] = test['ID'].str.rsplit('_', n=1).str[0]"
      ],
      "metadata": {
        "id": "uuyS_vaKtAGH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:07:26.524557Z",
          "iopub.execute_input": "2025-06-16T08:07:26.524871Z",
          "iopub.status.idle": "2025-06-16T08:07:26.541992Z",
          "shell.execute_reply.started": "2025-06-16T08:07:26.524854Z",
          "shell.execute_reply": "2025-06-16T08:07:26.541137Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "VTBy68nrxGdB",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:07:26.542728Z",
          "iopub.execute_input": "2025-06-16T08:07:26.543040Z",
          "iopub.status.idle": "2025-06-16T08:07:26.559323Z",
          "shell.execute_reply.started": "2025-06-16T08:07:26.543012Z",
          "shell.execute_reply": "2025-06-16T08:07:26.558695Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by prefix and assign the most frequent (mode) prediction as the group label\n",
        "grouped = test.groupby('prefix')['Target'].agg(lambda x: x.mode()[0]).reset_index()\n",
        "# Rename 'prefix' back to 'ID' to match the expected submission format\n",
        "grouped = grouped.rename(columns={'prefix': 'ID'})\n",
        "grouped.head()"
      ],
      "metadata": {
        "id": "XXhXsvERxfDK",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:07:26.560049Z",
          "iopub.execute_input": "2025-06-16T08:07:26.560257Z",
          "iopub.status.idle": "2025-06-16T08:07:26.604421Z",
          "shell.execute_reply.started": "2025-06-16T08:07:26.560235Z",
          "shell.execute_reply": "2025-06-16T08:07:26.603921Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final grouped predictions as a CSV file for submission\n",
        "grouped[['ID','Target']].to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "uRSITWHvmTpG",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-16T08:07:26.606209Z",
          "iopub.execute_input": "2025-06-16T08:07:26.606379Z",
          "iopub.status.idle": "2025-06-16T08:07:26.616753Z",
          "shell.execute_reply.started": "2025-06-16T08:07:26.606366Z",
          "shell.execute_reply": "2025-06-16T08:07:26.616127Z"
        }
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}